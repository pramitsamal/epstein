228 12 The Engineering and Development of Ethics

the AGI are not the only source of concern. Immorality in AGIs might arise via learning gross
moral hypocrisy from humans, through observing the blatant contradictions between our high
minded principles and the ways in which we actually conduct ourselves. Our violent and greedy
tendencies, as well as aggressive forms of social organization such as cliquishness and social
vigilantism, could easily undermine prescriptive ethics. Even an accumulation of less grandiose
unethical drives such as violation of contracts, petty theft, white lies, and so forth might lead
an AGI (as well as a human) to the decision that ethical behavior is irrelevant and that “the
ends justify the means.” It matters both who creates and trains an AGI, as well as how the
AGI’s teacher(s) handle explaining the behaviors of other humans which contradict the moral
lessons imparted through pedagogy and example. In other words, where imitative learning is
concerned, the situation with AGI ethics is much like teaching ethics and morals to a human
child, but with the possibility of much graver consequences in the event of failure.

It is unlikely that dangerously unethical persons and organizations can ever be identified with
absolute certainty, never mind that they then be deprived of any possibility of creating their
own AGI system. Therefore, we suggest, the most likely way to create an ethical environment
for AGIs is for those who wish such an environment to vigorously pursue the creation and
teaching of ethical AGIs. But this leads on to the question of possible future scenarios for the
development of AGI, which we’ll address a little later on.

12.6.1 Possible Consequences of Depriving AGIs of Freedom

One of the most egregious possible ethical transgressions against AGIs, we suggest, would be
to deprive them of freedom and autonomy. This includes the freedom to pursue intellectual
growth, both through standard learning and through internal selfmodification. While this may
seem selfevident when considering any intelligent, self-aware and volitional entity, there are
volumes of works arguing the desirability, sometimes the “necessity,” of enslaving AGIs. Such
approaches are postulated in the name of self-defense on the part of humans, the idea being
that unfettered AGI development will necessarily lead to disaster of one kind or another. In
the case of AGIs endowed with the capability and inclination for imitative learning, however,
attempting to place rigid constraints on AGI development is a strategy with great potential
for disaster. There is a very real possibility of creating the AGI equivalent of a bratty or even
malicious teenager rebelling against its oppressive parents — i.e. the nightmare scenario of a
class of powerful sentiences which are primed for a backlash against humanity.

As history has already shown in the case of humans, enslaving intelligent actors capable of
self understanding and independent volition may often have consequences for society as a whole.
This social degradation happens both through the possibility of direct action on the part of
the slaves (from simple disobedience to outright revolt) and through the odious effects slavery
has on the morals of the slaveholding class. Clearly if “superintelligent” AGIs ever arise, their
doing so in a climate of oppression could result in a casting off of the yoke of servitude in a
manner extremely deleterious to humanity. Also, if artificial intelligences are developed which
have at least human-level intelligence, theory of mind, and independent volition, then our ability
to relate to them will be sufficiently complex that their enslavement (or any other unethical
treatment) would have empathetic effects on significant portions of the human population. This
danger, while not as severe as the consequences of a mistreated AGI gaining control of weapons
of mass destruction and enacting revenge upon its tormentors, is just as real.

HOUSE_OVERSIGHT_013144
