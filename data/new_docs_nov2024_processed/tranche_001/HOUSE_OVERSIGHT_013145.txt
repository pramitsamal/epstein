12.6 The Ethical Treatment of AGIs 229

While the issue is subtle, our initial feeling is that the only ethical means by which to deprive
an AGI of the right to internal self modification is to write its code in such a way that it is
impossible for it to do so because it lacks the mechanisms by which to do this, as well as the
desire to achieve these mechanisms. Whether or not that is feasible is an open question, but
it seems unlikely. Direct self-modification may be denied, but what happens when that AGI
discovers compilers and computer programming? If it is intelligent and volitional, it can decide
to learn to rewrite its own code in the same way we perform that task. Because it is a designed
system, and its designers may be alive at the same time the AGI is, such an AGI would have a
distinct advantage over the human quest for medical self-modification. Even if any given AGI
could be provably deprived of any possible means of internal self-modification, if one single AGI
is given this ability by anyone, it may mean that particular AGI has such enormous advantages
over the compliant systems that it would render their influence moot. Since developers are
already giving software the means for self modification, it seems unrealistic to assume we could
just put the genie back into the bottle at this point. It’s better, in our view, to assume it will
happen, and approach that reality in a way which will encourage the AGI to use that capability
to benefit us as well as itself. Again, this leads on to the question of future scenarios for AGI
development — there are some scenarios in which restraint of AGI self-modification may be
possible, but the feasibility and desirability of these scenarios is needful of further exploration.

12.6.2 AGI Ethics as Boundaries Between Humans and AGIs
Become Blurred

Another important reason for valuing ethical treatment of AGIs is that the boundaries between
machines and people may increasingly become blurred as technology develops. As an exam-
ple, it’s likely that in future humans augmented by direct brain-computer integration (“neural
implants”) will be more able to connect directly into the information sharing network which po-
tentially comprises the distributed knowledge space of AGI systems. These neural cyborgs will
be part person, and part machine. Obviously, if there are radically different ethical standards
in place for treatment of humans versus AGIs, the treatment of cyborgs will be fraught with
logical inconsistencies, potentially leading to all sorts of problem situations.

Such cyborgs may be able to operate in such a way as to “share a mind” with an AGI or
another augmented human. In this case, a whole new range of ethical questions emerge, such
as: What does any one of the participant minds have the right to do in terms of interacting
with the others? Merely accepting such an arrangement should not necessarily be giving carte
blanche for any and all thoughts to be monitored by the other “joint thought” participants,
rather it should be limited only to the line of reasoning for which resources are being pooled.
No participant should be permitted to force another to accept any reasoning either — and in
the case with a mind-to-mind exchange, it may someday become feasible to implant ideas or
beliefs directly, bypassing traditional knowledge acquisition mechanisms and then letting the
new idea fight it out previously held ideas via internal revision. Also under such an arrangement,
if AGIs and humans do not have parity with respects to sentient rights, then one may become
subjugated to the will of the other in such a case.

Uploading presents a more directly parallel ethical challenge to AGIs in their probable initial
configuration. If human thought patterns and memories can be transferred into a machine in
such a way as that there is continuity of consciousness, then it is assumed that such an entity

HOUSE_OVERSIGHT_013145
