17.2 Measuring Incremental Progress Toward Human-Level AGI 309

about how to measure incremental progress. How do you tell when you’re 25% or 50% of the way
to having an AGI that can pass the Turing Test, or get an online university degree. Fooling 50%
of the Turing Test judges is not a good measure of being 50% of the way to passing the Turing
Test (that’s too easy); and passing 50% of university classes is not a good measure of being 50%
of the way to getting an online university degree (it’s too hard — if one had an AGI capable
of doing that, one would almost surely be very close to achieving the end goal). Measuring
incremental progress toward human-level AGI is a subtle thing, and we argue that the best way
to do it is to focus on particular scenarios and the achievement of specific competencies therein.

As we argued in Chapter 8 there are some theoretical reasons to doubt the possibility of
creating a rigorous objective test for partial progress toward AGI — a test that would be con-
vincing to skeptics, and impossible to game via engineering a system specialized to the test.
Fortunately, though we don’t need a test of this nature for the purposes of assessing our own
incremental progress toward advanced AGI, based on our knowledge about our own approach.

Based on the nature of the grand goals articulated above, there seems to be a very natural
approach to creating a set of incremental capabilities building toward AGI: to draw on our
copious knowledge about human cognitive development. This is by no means the only possible
path; one can envision alternatives that have nothing to do with human development (and those
might also be better suited to non-human AGIs). However, so much detailed knowledge about
human development is available — as well as solid knowledge that the human developmental
trajectory does lead to human-level AI — that the motivation to draw on human cognitive
development is quite strong.

The main problem with the human development inspired approach is that cognitive devel-
opmental psychology is not as systematic as it would need to be for AGI to be able to translate
it directly into architectural principles and requirements. As noted above, while early thinkers
like Piaget and Vygotsky outlined systematic theories of child cognitive development, these
are no longer considered fully accurate, and one currently faces a mass of detailed theories of
various aspects of cognitive development, but without an unified understanding. Nevertheless
we believe it is viable to work from the human-development data and understanding currently
available, and craft a workable AGI roadmap therefrom.

With this in mind, what we give next is a fairly comprehensive list of the competencies that
we feel AI systems should be expected to display in one or more of these scenarios in order
to be considered as full-fledged human level AGI systems. These competency areas have
been assembled somewhat opportunistically via a review of the cognitive and developmental
psychology literature as well as the scope of the current AI field. We are not claiming this as
a precise or exhaustive list of the competencies characterizing human-level general intelligence,
and will be happy to accept additions to the list, or mergers of existing list items, etc. What
we are advocating is not this specific list, but rather the approach of enumerating competency
areas, and then generating tasks by combining competency areas with scenarios.

We also give, with each competency, an example task illustrating the competency. The tasks
are expressed in the robot preschool context for concreteness, but they all apply to the virtual
preschool as well. Of course, these are only examples, and ideally to teach an AGI in a structured
way one would like to

e associate several tasks with each competency
e present each task in a graded way, with multiple subtasks of increasing complexity
® associate a quantitative metric with each task

HOUSE_OVERSIGHT_013225
