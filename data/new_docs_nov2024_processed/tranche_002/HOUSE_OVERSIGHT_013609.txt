probabilities, so that the sum of the decimal fraction parts of all the boxes in each
horizontal row add up to 100%, or as a real number, 1.00. Recall that in the

example we’ve been using, the binary expansion of the natural number 729, the

1 3
transition incidence matrix is M; = 44 and its Markov matrix is top row, 1/4, 3/4

0.25 0.75

and bottom row 3/5 , 2/5, i.e. Mrp = Ane Od

. Matrix multiplication of Mz» by itself

repeatedly is equivalent to tracking the temporal evolution of the transition matrix’s
probabilities until the resulting matrices move toward, converge onto, a steady state;
each self matrix multiplication step represents what results from the passage of one
unit of time. The convergence to equilibrium values is continuous and gradual.
When the steady state is reached, both rows become identical. For this example,

0.5125 0.4875. 4 _ 0.4527 0.5472 g _ 0.4445 0.5554_

Mi x Mip or Min? = > Mip” = =
te Sue 9.3900 0.6100” ~——«0.4377-0.5622 0.4443. 0.5556

te _ 0.4444 0.5555

= which for the first four decimal places remain the same for
0.4444 0.5555

tp

additional times of self multiplication. Note the convergence of the top and bottom
rows to the same asymptotic values. Books discussing the multiplicative and other
behavior of these nonnegative matrices are numerous and frequently appear in
matrix algebra texts under the rubric of the Frobenius-Perron theorems.

Using the entropy formalism of Claude Shannon as developed previously, Hy
is computed as the sum across either of the identical rows of each probability times
its logarithm, px /og(p.p2x/og(p2)) remembering from above that we are working in
base 2 logarithms and to change the minus sign (resulting from taking the
logarithms of decimal fractions) to plus: Hy (Mip) = .4444 x log(.4444) + 5555 x
log(.5555) = .9911 The nonuniformity of the box occupancy probabilities is reflected
in the difference between the topological (maximal estimate) and metric (minimal
estimate) entropies and is therefore quantifiable and computable: H7 - Hy # 0 = 1.00
- 0.9911 = 0. 0089. If the maximal and minimal estimates of the entropy were equal

and all the probabilities boxes in each row asymptotically contained the same

109

HOUSE_OVERSIGHT_013609
