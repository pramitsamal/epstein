the long run, there is no distinction between arming ourselves and arming our enemies.”
(p. 129) The Information Age is also the Dysinformation Age.

What can we do? We need to rethink our priorities with the help of the passionate
but flawed analyses of Wiener, Weizenbaum, and the other serious critics of our
technophilia. A key phrase, it seems to me, is Wiener’s almost offhand observation,
above, that “these machines” are “helpless by themselves.” As I have been arguing
recently, we’re making tools, not colleagues, and the great danger is not appreciating the
difference, which we should strive to accentuate, marking and defending it with political
and legal innovations.

Perhaps the best way to see what is being missed 1s to note that Alan Turing
himself suffered an entirely understandable failure of imagination in his formulation of
the famous Turing Test. As everyone knows, it is an adaptation of his “imitation game,”
in which a man, hidden from view and communicating verbally with a judge, tries to
convince the judge that he is in fact a woman, while a woman, also hidden and
communicating with the judge, tries to convince the judge that she is the woman. Turing
reasoned that this would be a demanding challenge for a man (or for a woman pretending
to be a man), exploiting a wealth of knowledge about how the other sex thinks and acts,
what they tend to favor or ignore. Surely (ding!)?, any man who could beat a woman at
being perceived to be a woman would be an intelligent agent. What Turing did not
foresee is the power of deep-learning AI to acquire this wealth of information in an
exploitable form without having to understand it. Turing imagined an astute and
imaginative (and hence conscious) agent who cunningly designed his responses based on
his detailed “theory” of what women are likely to do and say. Top-down intelligent
design, in short. He certainly didn’t think that a man, winning the imitation game, would
somehow become a woman; he imagined that there would still be a man’s consciousness
guiding the show. The hidden premise in Turing’s almost-argument was: Only a
conscious, intelligent agent could devise and control a winning strategy in the imitation
game. And so it was persuasive to Turing (and others, including me, still a stalwart
defender of the Turing Test) to argue that a “computing machine” that could pass as
human in a contest with a human might not be conscious in just the way a human being
is, but would nevertheless have to be a conscious agent of some kind. I think this is still a
defensible position—the only defensible position—but you have to understand how
resourceful and ingenious a judge would have to be to expose the shallowness of the
facade that a deep-learning AI (a tool, not a colleague) could present.

What Turing didn’t foresee is the uncanny ability of superfast computers to sift
mindlessly through Big Data, of which the Internet provides an inexhaustible supply,
finding probabilistic patterns in human activity that could be used to pop “authentic’-
seeming responses into the output for almost any probe a judge would think to offer.
Wiener also underestimates this possibility, seeing the tell-tale weakness of a machine in
not being able to

take into account the vast range of probability that characterizes the human
situation. (p.181)

° The surely alarm (the habit of having a bell ring in your head whenever you sce the word in an argument)
is described and defended by me in Jntuition Pumps and Other Tools for Thinking (2013).

44

HOUSE_OVERSIGHT_016264
