1.8 Virtually and Robotically Embodied AI 11

tokens (Atoms) in the AtomSpace, allowing it to be located by various cognitive processes, and
associated with other memory items of any type.

So for instance an OpenCog AI system has an AtomSpace, plus some specialized knowledge
stores linked into the AtomSpace; and it also has specific algorithms acting on the AtomSpace
and appropriate specialized stores corresponding to each type of memory. Each of these algo-
rithms is complex and has its own story; for instance (an incomplete list, for more detail see
the following section of this Introduction):

e Declarative knowledge is handled using Probabilistic Logic Networks, described in Chapter
34 and others;

e Procedural knowledge is handled using MOSES, a probabilistic evolutionary learning algo-
rithm described in Chapter 21 and others;

e Attentional knowledge is handled by ECAN (economic attention allocation), described in
Chapter 23 and others;

e OpenCog contains a language comprehension system called RelEx that takes English sen-
tences and turns them into nodes and links in the AtomSpace. It’s currently being ex-
tended to handle Chinese. RelEx handles mostly declarative knowledge but also involves
some procedural knowledge for linguistic phenomena like reference resolution and semantic
disambiguation.

But the crux of the CogPrime cognitive architecture is not any particular cognitive process,
but rather the way they all work together using cognitive synergy.

1.8 Virtually and Robotically Embodied AI

Another issue that will arise frequently in these pages is embodiment. There’s a lot of debate in
the AI community over whether embodiment is necessary for advanced AGI or not. Personally,
we doubt it’s necessary but we think it’s extremely convenient, and are thus considerably
interested in both virtual world and robotic embodiment. The CogPrime architecture itself is
neutral on the issue of embodiment, and it could be used to build a mathematical theorem
prover or an intelligent chat bot just as easily as an embodied AGI system. However, most of
our attention has gone into figuring out how to use CogPrime to control embodied agents in
virtual worlds, or else (to a lesser extent) physical robots. For instance, during 2011-2012 we
are involved in a Hong Kong government funded project using OpenCog to control video game
agents in a simple game world modeled on the game Minecraft [GPC™ 11].

Current virtual world technology has significant limitations that make them far less than
ideal from an AGI perspective, and in Chapter 16 we will discuss how they can be remedied.
However, for the medium-term future virtual worlds are not going to match the natural world
in terms of richness and complexity — and so there’s also something to be said for physical
robots that interact with all the messiness of the real world.

With this in mind, in the Artificial Brain Lab at Xiamen University in 2009-2010, we con-
ducted some experiments using OpenCog to control the Nao humanoid robot [GD09]. The goal
of that work was to take the same code that controls the virtual dog and use it to control the
physical robot. But it’s harder because in this context we need to do real vision processing
and real motor control. A similar project is being undertaken in Hong Kong at time of writ-
ing, involving a collaboration between OpenCog AI developers and David Hanson’s robotics

HOUSE_OVERSIGHT_012927
