226 12 The Engineering and Development of Ethics

The implications of these ideas for ethical instruction are complex and won’t be fully elabo-
rated here, but a few of them are compact and obvious:

1. The teacher(s) must be observed to follow their own ethical principles, in a variety of
contexts that are meaningful to the AGI

2. The system of ethics must be relevant to the recipient’s life context, and embedded within
their understanding of the world.

3. Ethical principles must be grounded in both theory-of mind thought experiments (empha-
sizing logical coherence), and in real life situations in which the ethical trainee is required
to make a moral judgment and is rewarded or reproached by the teacher(s), including the
imparting of explanatory augmentations to the teachings regarding the reason for the par-
ticular decision on the part of the teacher.

Finally, harking forward to the next section which emphasizes the importance of respecting
the freedom of AGIs, we note that it is implicit in our approach to AGI ethics instruction
that we consider the student, the AGI system, as an autonomous agent with its own “will”
and its own capability to flexibly adapt to its environment and experience. We contend that
the creation of ethical formations obeying the above imperatives is not antithetical to the
possession of a high degree of autonomy on the part of AGI systems. On the contrary, to have
any chance of succeeding, it requires fairly cognitively autonomous AGI systems. When we
discuss the idea of ethical formulations that are unlikely to be undermined by the ongoing
self-revision of an AGI mind, we are talking about those which are sufficiently believable that
a volitional intelligence with the capacity to revise its knowledge (“change its mind”) will find
the formulations sufficiently convincing that there will be little incentive to experiment with
potentially disastrous ethical alternatives. The best hope of achieving this is via the human
mentors and trainers setting a good example in a context supporting rich interaction and
observation, and presenting compelling ethical arguments that are coherent with the system’s
experience.

12.6 The Ethical Treatment of AGIs

We now make some more general comments about the relation of the Golden Rule and its
elaborations in an AGI context. While the Golden Rule is considered somewhat commonsensical
as a maxim for guiding human-human relationships, it is surprisingly controversial in terms of
historical theories of AGI ethics. At its essence, any “Golden Rule” approach to AGI ethics
involves humans treating AGIs ethically by — in some sense; at some level of abstraction —
treating them as we wish to ourselves be treated. It’s worth pointing out the wild disparity
between the Golden Rule approach and Asimov’s laws of robotics, which are arguably the first
carefully-articulated proposal regarding AGI ethics (see Table 12.7).

Of course, Asimov’s laws were designed to be flawed — otherwise they would have led to
boring fiction. But the sorts of flaws Asimov exploited in his stories are different than the
flaw we wish to point out here — which is that the laws, especially the second one, are highly
asymmetrical (they involve doing unto robots things that few humans would want done unto
them) and are also arguably highly unethical to robots. The second law is tantamount to a call
for robot slavery, and it seems unlikely that any intelligence capable of learning, and of volition,
which is subjected to the second law would desire to continue obeying the zeroth and first laws

HOUSE_OVERSIGHT_013142
