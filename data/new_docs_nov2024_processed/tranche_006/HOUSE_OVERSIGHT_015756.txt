66 Are the Androids Dreaming Yet?

The exchange of notes goes on for a few days and the two seem to be
getting on well. There is even a little romance in the air. When the week is
over I open the door and the two meet. The graduate student says, “Hello.
It’s nice to finally meet you in person.’ The man is puzzled because, of
course, she has spoken to him in Chinese. He knows no Chinese.

“Tm terribly sorry, but I don’t speak Chinese,” he says.

She is puzzled, “But I spoke with you this last week!”

“No, I really don't speak it,” he says.

And, of course, he is telling the truth. The book he has been using
contains the rules for answering questions in Chinese, but he has
absolutely no knowledge of the language. I'll leave to your imagination
whether the two strike up a real relationship and live happily ever after.

This is the Story of the Chinese Room. The setup is able to fool
someone into believing there is a Chinese speaking person in the room,
yet there is not. Where does the understanding of Chinese lie? The man
definitely does not understand Chinese. And the book clearly does not
understand Chinese because it is an inanimate object. Yet the person
outside the room is convinced she is communicating with a Chinese
speaker. The analogy to a computer is clear. The book is software and
the man blindly following instructions is the hardware. John Searle,
who devised the thought experiment uses it to show computers can
never understand because there is no place in a mechanistic system for
understanding to exist.

The Chinese Room has sparked huge argument in philosophical
circles; let me boil it down to its simplest form. First, let's refute Searle's
position with the ‘System Argument.

The man plus the book form a system. Systems understand; their
individual components do not. My blood does not understand. My brain
without blood would not understand — it would be dead! Plug my brain
into a good supply of blood; add a dash of glucose, and it will understand
the most complex of things.

The systems argument is elegant and most scientists think this is the
definitive argument against Searle, but Searle has a neat way to counter
it. “Imagine”, he says, “that the man memorizes the book and leaves the
room. Now there is no system, there is just the man, but the man still does
not understand Chinese; he is just parroting rote-memorized words and
rules.” Computers, Searle argues, process syntax — the rules of language;
humans understand semantics — the contextual meaning of language.

Artificial Intelligence (AI) proponents hate the Searle argument.
They believe the memorization of a set of words and rules is exactly what
gives us knowledge of Chinese. That is why we go to school!

HOUSE_OVERSIGHT_015756
