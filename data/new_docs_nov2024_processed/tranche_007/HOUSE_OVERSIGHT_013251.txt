Glossary of Specialized Terms 335

Knowledge Base: A shorthand for the totality of knowledge possessed by an intelligent
system during a certain interval of time (whether or not this knowledge is explicitly rep-
resented). Put differently: this is an intelligence’s total memory contents (inclusive of all
types of memory) during an interval of time.

Language Comprehension: The process of mapping natural language speech or text into
a more “cognitive”, largely language-independent representation. In OpenCog this has been
done by various pipelines consisting of dedicated natural language processing tools, e.g. a
pipeline: text — Link Parser — RelEx > RelEx2Frame — Frame2Atom Atomspace; and
alternatively a pipeline Link Parser > Link2Atom — Atomspace. It would also be possi-
ble to do language comprehension purely via PLN and other generic OpenCog processes,
without using specialized language processing tools.

Language Generation: The process of mapping (largely language-independent) cognitive
content into speech or text. In OpenCog this has been done by various pipelines consisting of
dedicated natural language processing tools, e.g. a pipeline: Atomspace > NLGen — text;
or more recently Atomspace — Atom2Link — surface realization — text. It would also be
possible to do language generation purely via PLN and other generic OpenCog processes,
without using specialized language processing tools.

Language Processing: Processing of human language is decomposed, in CogPrime, into
Language Comprehension, Language Generation, and Dialogue Control.

Learning: In general, the process of a system adapting based on experience, in a way that
increases its intelligence (its ability to achieve its goals). The theory underlying CogPrime
doesn’t distinguish learning from reasoning, associating, or other aspects of intelligence.
Learning Server: In some OpenCog configurations, this refers to a software server that
performs “offline” learning tasks (e.g. using MOSES or hillclimbing), and is in communica-
tion with an Operational Agent Controller software server that performs real-time agent
control and dispatches learning tasks to and receives results from the Learning Server.
Linguistic Links: A catch-all term for Atoms explicitly representing linguistic content,
e.g. WordNode, SentenceNode, CharacterNode.

Link: A type of Atom, representing a relationship among one or more Atoms. Links and
Nodes are the two basic kinds of Atoms.

Link Parser: A natural language syntax parser, created by Sleator and Temperley at
Carnegie-Mellon University, and currently used as part of OpenCogPrime’s natural language
comprehension and natural language generation system.

Link2Atom: A system for translating link parser links into Atoms. It attempts to resolve
precisely as much ambiguity as needed in order to translate a given assemblage of link parser
links into a unique Atom structure.

Lobe: A term sometimes used to refer to a portion of a distributed Atomspace that lives
in a single computational process. Often different lobes will live on different machines.
Localized Memory: Memory that stores each item using a small number of closely-
connected elements.

Logic: In an OpenCog context, this usually refers to a set of formal rules for translating
certain combinations of Atoms into “conclusion” Atoms. The paradigm case at present is the
PLN probabilistic logic system, but OpenCog can also be used together with other logics.
Logical Links: Any Atoms whose truth values are primarily determined or adjusted via
logical rules, e.g. PLN’s InheritanceLink, SimilarityLink, ImplicationLink, etc. The term
isn’t usually applied to other links like HebbianLinks whose semantics isn’t primarily logic-

HOUSE_OVERSIGHT_013251
