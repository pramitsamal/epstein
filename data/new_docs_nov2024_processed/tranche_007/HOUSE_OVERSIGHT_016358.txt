Social sampling, very simply, is looking around you at the actions of people who
are like you, finding what’s popular, and then copying it if it seems like a good idea to
you. Idea propagation has this popularity function driving it, but individual adoption also
is about figuring out how the idea works for the individual—a reflective attitude. When
you combine social sampling and personal judgment, you get superior decision making.
That’s amazing, because now we have a mathematical recipe for doing with humans what
all those AI techniques are doing with dumb computer neurons. We have a way of
putting people together to make better decisions, given more and more experience.

So, what happens in the real world? Why don’t we do this all the time? Well,
people are good at it, but there are ways it can run amok. One of these is through
advertising, propaganda, or “fake news.” There are many ways to get people to think
something is popular when it’s not, and this destroys the usefulness of social sampling.
The way you can make groups of people smarter, the way you can make human ATI, will
work only if you can get feedback to them that’s truthful. It must be grounded on
whether each person’s actions worked for them or not.

That’s the key to AI mechanisms, too. What they do is analyze whether they
performed correctly. If so, plus one; if not, minus one. We need that truthful feedback to
make this human mechanism work well, and we need good ways of knowing about what
other people are doing so that we can correctly assess popularity and the likelihood of
this being a good choice.

The next step is to build this credit-assignment function, this feedback function,
for people, so that we can make a good human-artificial ecosystem—a smart organization
and a smart culture. In a way, we need to duplicate some of the early insights that
resulted in, for instance, the U.S. census—trying to find basic facts that everybody can
agree on and understand so that the transmission of knowledge and culture can happen in
a way that’s truthful and social sampling can function efficiently.

We can address the problem of building an accurate credit-assignment function in
many different settings. In companies, for instance, it can be done with digital ID badges
that reveal who’s connected to whom, so that we can assess the pattern of connections in
relation to the company’s results on a daily or weekly basis. The credit-assignment
function asks whether those connections helped solve problems, or helped invent new
solutions, and reinforces the helpful connections. When you can get that feedback
quantitatively—which is difficult, because most things aren’t measured quantitatively—
both the productivity and the innovation rate within the organization can be significantly
improved. This is, for instance, the basis of Toyota’s “continuous improvement” method.

A next step is to try to do the same thing but at scale, something I refer to as
building a trust network for data. It can be thought of as a distributed system like the
Internet, but with the ability to quantitatively measure and communicate the qualities of
human society, in the same way that the U.S. census does a pretty good job of telling us
about population and life expectancy. We are already deploying prototype examples of
trust networks at scale in several countries, based on the data and measurement standards
laid out in the U.N. Sustainable Development Goals.

On the horizon is a vision of how we can make humanity more intelligent by
building a human AI. It’s a vision composed of two threads. One is data that we can all
trust—data that have been vetted by a broad community, data where the algorithms are
known and monitored, much like the census data we all automatically rely on as at least

138

HOUSE_OVERSIGHT_016358
