In computer terms, I started out with a “generative model” that includes abstract
concepts like greed and deception and describes the process that produces email scams.
That lets me recognize the classic Nigerian email spam, but it also lets me imagine many
different kinds of possible spam. When I get the journal email, I can work backward:
“This seems like just the kind of mail that would come out of a spam-generating
process.”

The new excitement about AI comes because AI researchers have recently
produced powerful and effective versions of both these learning methods. But there is
nothing profoundly new about the methods themselves.

Bottom-up Deep Learning

In the 1980s, computer scientists devised an ingenious way to get computers to detect
patterns in data: connectionist, or neural-network, architecture (the “neural” part was, and
still is, metaphorical). The approach fell into the doldrums in the ’90s but has recently
been revived with powerful “deep-learning” methods like Google’s DeepMind.

For example, you can give a deep-learning program a bunch of Internet images
labeled “cat,” others labeled “house,” and so on. The program can detect the patterns
differentiating the two sets of images and use that information to label new images
correctly. Some kinds of machine learning, called unsupervised learning, can detect
patterns in data with no labels at all; they simply look for clusters of features—what
scientists call a factor analysis. In the deep-learning machines, these processes are
repeated at different levels. Some programs can even discover relevant features from the
raw data of pixels or sounds; the computer might begin by detecting the patterns in the
raw image that correspond to edges and lines and then find the patterns in those patterns
that correspond to faces, and so on.

Another bottom-up technique with a long history is reinforcement learning. In the
1950s, B. F. Skinner, building on the work of John Watson, famously programmed
pigeons to perform elaborate actions—even guiding air-launched missiles to their targets
(a disturbing echo of recent AI) by giving them a particular schedule of rewards and
punishments. The essential idea was that actions that were rewarded would be repeated
and those that were punished would not, until the desired behavior was achieved. Even
in Skinner’s day, this simple process, repeated over and over, could lead to complex
behavior. Computers are designed to perform simple operations over and over on a scale
that dwarfs human imagination, and computational systems can learn remarkably
complex skills in this way.

For example, researchers at Google’s DeepMind used a combination of deep
learning and reinforcement learning to teach a computer to play Atari video games. The
computer knew nothing about how the games worked. It began by acting randomly and
got information only about what the screen looked like at each moment and how well it
had scored. Deep learning helped interpret the features on the screen, and reinforcement
learning rewarded the system for higher scores. The computer got very good at playing
several of the games, but it also completely bombed on others just as easy for humans to
master.

A similar combination of deep learning and reinforcement learning has enabled
the success of DeepMind’s AlphaZero, a program that managed to beat human players at
both chess and Go, equipped only with a basic knowledge of the rules of the game and

154

HOUSE_OVERSIGHT_016957
