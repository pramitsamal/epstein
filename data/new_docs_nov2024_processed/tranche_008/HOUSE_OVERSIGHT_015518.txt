306 M. Hoffman et al.

publicized self-immolation, and not a breach of a threshold in, say, the quality of life
of citizens or the level of corruption. This explanation requires simply that we rec-
ognize revolutions as a coordination problem (as argued in Morris & Shin, 2002;
Chwe, 2013), where each revolutionary chooses whether to revolt, and each is better
off revolting only if sufficiently many others revolt.

Quirks of Altruism and the Repeated Prisoner’s Dilemma
with Incomplete Information

The Repeated Prisoner's Dilemma has famously been used as an explanation for
the evolution of cooperation among non-kin (Axelrod & Hamilton, 1981; Dawkins,
2006; Pinker, 2003; Trivers, 1971). In this section, we show how the same basic
model can be used to explain many of the quirky features of our pro-social prefer-
ences and ideologies.

Recall that in the Prisoner’s Dilemma, each of two players simultaneously
chooses whether to cooperate. Cooperation reduces a player’s own payoffs by c>0
while increasing the other’s payoffs by b>c. The only Nash equilibrium is for nei-
ther player to cooperate. In the Repeated Prisoner’s Dilemma, the players play a
string of Prisoner’s Dilemmas. That is, after the players play a Prisoner’s Dilemma,
they learn what their opponent did and play another Prisoner’s Dilemma against the
same opponent with probability 6 (and the game ends with probability 1-6). As is
well known in the evolutionary literature, there are equilibria in which players end
up cooperating, provided 6>c/b. In all such equilibria, cooperation is sustained
because any defection by one player causes the other player to defect. This is called
reciprocity. As the reader is surely familiar, there is ample evidence for the Repeated
Prisoner’s Dilemma as a basis for cooperation from computer simulations (e.g.,
Axelrod, 1984) and animal behavior (e.g., Wilkinson, 1984). The model can be
extended to explain contributions to public goods if, after deciding whether to con-
tribute to a public good, players play a Repeated Prisoner’s Dilemma (see, e.g.,
Panchanathan & Boyd, 2004) (Fig. 5).

The key to understanding these quirks is that players often have incomplete
information. For example:

1. Players do not always observe contributions. It is intuitive that, for cooperation
to occur in equilibrium, contributions need to be observed with sufficiently high
probability.

2, Others cannot always tell whether a player had an opportunity to contribute. For
defection to be penalized, it must be the case that others can tell that a player had
the opportunity to cooperate and did not (.e. the player should not be able to hide
the fact that there was an opportunity to cooperate).

3. Sometimes, there are two ways to cooperate, and one has a higher benefit, b.
Then, the only way this more effective type of cooperation can be sustained in
equilibrium is if others know which cooperative act is more effective.

HOUSE_OVERSIGHT_015518
