7.3 Toward a Formal Characterization of Real-World General Intelligence 135

7.3 Toward a Formal Characterization of Real-World General
Intelligence

Having defined what we mean by an agent acting in an environment, we now turn to the
question of what it means for such an agent to be “intelligent.”

As we have reviewed extensively in Chapter 2 above, “intelligence” is a commonsense, “folk
psychology” concept, with all the imprecision and contextuality that this generally entails.
One cannot expect any compact, elegant formalism to capture all of its meanings. Even in
the psychology and AI research communities, divergent definitions abound; Legg and Hutter
[L107a] lists and organizes 70+ definitions from the literature.

Practical study of natural intelligence in humans and other organisms, and practical de-
sign, creation and instruction of artificial intelligences, can proceed perfectly well without an
agreed-upon formalization of the “intelligence” concept. Some researchers may conceive their
own formalisms to guide their own work, others may feel no need for any such thing.

But nevertheless, it is of interest to seek formalizations of the concept of intelligence, which
capture useful fragments of the commonsense notion of intelligence, and provide guidance for
practical research in cognitive science and AI. A number of such formalizations have been given
in recent decades, with varying degrees of mathematical rigor. Perhaps the most carefully-
wrought formalization of intelligence so far is the theory of “universal intelligence” presented by
Shane Legg and Marcus Hutter in [LI07b], which draws on ideas from algorithmic information
theory.

Universal intelligence captures a certain aspect of the “intelligence” concept very well, and
has the advantage of connecting closely with ideas in learning theory, decision theory and
computation theory. However, the kind of general intelligence it captures best, is a kind which
is in a sense more general in scope than human-style general intelligence. Universal intelligence
does capture the sense in which humans are more intelligent than worms, which are more
intelligent than rocks; and the sense in which theoretical AGI systems like Hutter’s AIXI or
AIXI® [Hut05] would be much more intelligent than humans. But it misses essential aspects
of the intelligence concept as it is used in the context of intelligent natural systems like humans
or real-world AI systems.

Our main goal in this section is to present variants of universal intelligence that better
capture the notion of intelligence as it is typically understood in the context of real-world
natural and artificial systems. The first variant we describe is pragmatic general intelligence,
which is inspired by the intuitive notion of intelligence as “the ability to achieve complex goals
in complex environments,” given in [Goe93a]. After assuming a prior distribution over the
space of possible environments, and one over the space of possible goals, one then defines the
pragmatic general intelligence as the expected level of goal-achievement of a system relative
to these distributions. Rather than measuring truly broad mathematical general intelligence,
pragmatic general intelligence measures intelligence in a way that’s specifically biased toward
certain environments and goals.

Another variant definition is then presented, the efficient pragmatic general intelligence,
which takes into account the amount of computational resources utilized by the system in
achieving its intelligence. Some argue that making efficient use of available resources is a defining
characteristic of intelligence, see e.g. [Wan06].

A critical question left open is the characterization of the prior distributions corresponding
to everyday human reality; we give a semi-formal sketch of some ideas on this in Chapter 9
below, where we present the notion of a “communication prior,” which assigns a probability

HOUSE_OVERSIGHT_013051
