12.3 The Value of an Explicit Goal System 209

12.3 The Value of an Explicit Goal System

One of the subtle issues confronted in the quest to design ethical AGIs is how closely one
wants to emulate human ethical judgment and behavior. Here one confronts the brute fact
that, even according to their own deeply-held standards, humans are not all that ethical. One
high-level conclusion we came to very early in the process of designing CogPrime is that, just as
humans are not the most intelligent minds achievable, they are also not the most ethical minds
achievable. Even if one takes human ethics, broadly conceived, as the standard — there are
almost surely possible AGI systems that are much more ethical according to human standards
than nearly all human beings. This is not mainly because of ethics-specific features of the
human mind, but rather because of the nature of the human motivational system, which leads
to many complexities that drive humans to behaviors that are unethical according to their own
standards. So, one of the design decisions we made for CogPrime — with ethics as well as other
reasons in mind — was not to closely imitate the human motivational system, but rather to craft
a novel motivational system combining certain aspects of the human motivational system with
other profoundly non-human aspects.

On the other hand, the design of ethical AGI systems still has a lot to gain from the study
of human ethical cognition and behavior. Human ethics has many aspects, which we associate
here with the different types of memory, and it’s important that AGI systems can encompass
all of them. Also, as we will note below, human ethics develops in childhood through a series
of natural stages, parallel to and entwined with the cognitive developmental stages reviewed in
Chapter 11 above. We will argue that for an AGI with a virtual or robotic body, it makes sense
to think of ethical development as proceeding through similar stages. In a CogPrime context,
the particulars of these stages can then be understood in terms of the particulars of CogPrime’s
cognitive processes — which brings AGI ethics from the domain of theoretical abstraction into
the realm of practical algorithm design and education.

But even if the human stages of ethical development make sense for non-human AGIs, this
doesn’t mean the particulars of the human motivational system need to be replicated in these
AGIs, regarding ethics or other matters. A key point here is that, in the context of human
intelligence, the concept of a goal is a descriptive abstraction. But in the AGI context, it
seems quite valuable to introduce goals as explicit design elements (which is what is done in
CogPrime ) — both for ethical reasons and for broader AGI design reasons.

Humans may adopt goals for a time and then drop them, may pursue multiple conflicting
goals simultaneously, and may often proceed in an apparently goal-less manner. Sometimes the
goal that a person appears to be pursuing, may be very different than the one they think they’re
pursuing. Evolutionary psychology [BDL93] argues that, directly or indirectly, all humans are
ultimately pursuing the goal of maximizing the inclusive fitness of their genes — but given the
complex mix of evolution and self-organization in natural history [Sal93], this is hardly a general
explanation for human behavior. Ultimately, in the human context, goal is best thought of
as a frequently useful heuristic concept.

AGI systems, however, need not emulate human cognition in every aspect, and may be
architected with explicit goal systems. This provides no guarantee that said AGI systems will
actually pursue the goals that their goal systems specify — depending on the role that the goal
system plays in the overall system dynamics, sometimes other dynamical phenomena might
intervene and cause the system to behave in ways opposed to its explicit goals. However, we
submit that this design sketch provides a better framework than would exist in an AGI system
closely emulating the human brain.

HOUSE_OVERSIGHT_013125
