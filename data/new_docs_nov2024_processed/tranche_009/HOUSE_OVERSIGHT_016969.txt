THE RIGHTS OF MACHINES
George M. Church

George M. Church is Robert Winthrop Professor of Genetics at Harvard Medical
School; Professor of Health Sciences and Technology, Harvard-MIT; and co-author
(with Ed Regis) of Regenesis: How Synthetic Biology Will Reinvent Nature and
Ourselves.

In 1950, Norbert Wiener’s Zhe Human Use of Human Beings was at the cutting edge of
vision and speculation in proclaiming that

the machine like the djinnee, which can learn and can make decisions on the
basis of its learning, will in no way be obliged to make such decisions as we
should have made, or will be acceptable to us. ... Whether we entrust our
decisions to machines of metal, or to those machines of flesh and blood which
are bureaus and vast laboratories and armies and corporations, . . . [t]he hour is
very late, and the choice of good and evil knocks at our door.

But this was his book’s denouement, and it has left us hanging now for sixty-eight
years, lacking not only prescriptions and proscriptions but even a well-articulated
“problem statement.” We have since seen similar warnings about the threat of our
machines, even in the form of outreach to the masses, via films like Colossus: The Forbin
Project (1970), The Terminator (1984), The Matrix (1999), and Ex Machina (2015). But
now the time is ripe for a major update, with fresh, new perspectives—notably focused
on generalizations of our “human” rights and our existential needs.

Concern has tended to focus on “us versus them [robots]” or “grey goo
[nanotech]” or “monocultures of clones [bio].” To extrapolate current trends: What if we
could make or grow almost anything and engineer any level of safety and efficacy
desired? Any thinking being (made of any arrangement of atoms) could have access to
any technology.

Probably we should be less concerned about us-versus-them and more concerned
about the rights of all sentients in the face of an emerging unprecedented diversity of
minds. We should be harnessing this diversity to minimize global existential risks, like
supervolcanoes and asteroids.

But should we say “should”? (Disclaimer: In this and many other cases, when a
technologist describes a societal path that “could,” “would,” or “should” happen, this
doesn’t necessarily equate to the preferences of the author. It could reflect warning,
uncertainty, and/or detached assessment.) Roboticist Gianmarco Veruggio and others
have raised issues of roboethics since 2002; the U.K. Department of Trade and Industry
and the RAND spin-off Institute for the Future have raised issues of robot rights since
2006.

“Ts versus ought”

It is commonplace to say that science concerns “is,” not “ought.” Stephen Jay Gould’s
“non-overlapping magisteria” view argues that facts must be completely distinct from
values. Similarly, the 1999 document Science and Creationism from the U.S. National
Academy of Sciences noted that “science and religion occupy two separate realms.” This

166

HOUSE_OVERSIGHT_016969
