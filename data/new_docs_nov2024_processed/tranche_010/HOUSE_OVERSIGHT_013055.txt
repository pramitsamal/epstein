7.3 Toward a Formal Characterization of Real-World General Intelligence 139

decays exponentially, whereas an assumptive distribution over environments might decay at
some other rate. This issue seems to merit further mathematical investigation.

7.3.4 Incorporating Computational Cost

Let r44,g,7 be a probability distribution describing the amount of computational resources con-
sumed by an agent 7 while achieving goal g over time-scale J. This is a probability distribution
because we want to account for the possibility of nondeterministic agents. 50, 77,..97r(Q) tells
the probability that @ units of resources are consumed. For simplicity we amalgamate space
and time resources, energetic resources, etc. into a single number Q, which is assumed to live
in some subset of the positive reals. Space resources of course have to do with the size of the
system’s memory. Then we may define

Definition 6 The efficient pragmatic general intelligence of an agent x with resource
consumption Nru,9,7, relative to the distribution v over environments and the distribution +
over goals, is its expected performance with respect to goals drawn from y in environments drawn
from v, over the time-scales natural to the goals, normalized by the amount of computational
effort expended to achieve each goal; that is,

_ YL) Y(G, Le w9,T(@) ya
Trg) = » ail Q mst Viig.T
HEB,GEG,Q,T

(in those cases where this sum is convergent).

This is a measure that rates an agent’s intelligence higher if it uses fewer computational
resources to do its business. Roughly, it measures reward achieved per spacetime computation
unit.

Note that, by abandoning the universal prior, we have also abandoned the proof of conver-
gence that comes with it. In general the sums in the above definitions need not converge; and
exploration of the conditions under which they do converge is a complex matter.

7.3.5 Assessing the Intelligence of Real-World Agents

The pragmatic and efficient pragmatic general intelligence measures are more “realistic” than
the Legg and Hutter universal intelligence measure, in that they take into account the innate
biasing and computational resource restrictions that characterize real-world intelligence. But as
discussed earlier, they still live in “fantasy-land” to an extent — they gauge the intelligence of an
agent via a weighted average over a wide variety of goals and environments; and they presume
a simplistic relationship between agents and rewards that does not reflect the complexities
of real-world cognitive architectures. It is not obvious from the foregoing how to apply these
measures to real-world intelligent systems, which lack the ability to exist in such a wide variety
of environments within their often brief lifespans, and mostly go about their lives doing things
other than pursuing quantified external rewards. In this brief section we describe an approach
to bridging this gap. The treatment is left semi-formal in places.

HOUSE_OVERSIGHT_013055
