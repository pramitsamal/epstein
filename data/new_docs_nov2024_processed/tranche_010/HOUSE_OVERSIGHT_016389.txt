Even though a supercomputer can “train” a clone of zemself in seconds, the
energy cost of producing a mature silicon clone is comparable. Engineering (Homo)
prodigies might make a small impact on this slow process, but speeding up development
and implanting extensive memory (as DNA-exabytes or other means) could reduce
duplication time of a bio-computer to close to the doubling time of cells (ranging from
eleven minutes to twenty-four hours). The point is that while we may not know what
ratio of bio/homo/nano/robo hybrids will be dominant at each step of our accelerating
evolution, we can aim for high levels of humane, fair, and safe treatment (“use”) of one
another.

Bills of Rights date back to 1689 in England. FDR proclaimed the “Four
Freedoms”’—freedom of speech, freedom of conscience, freedom from fear, and freedom
from want. The U.N.’s Universal Declaration of Human Rights in 1948 included the
right to life; the prohibition of slavery; defense of rights when violated; freedom of
movement; freedom of association, thought, conscience, and religion; social, economic,
and cultural rights; duties of the individual to society; and prohibition of use of rights in
contravention of the purposes and principles of the United Nations.

The “universal” nature of these rights is not universally embraced and is subject
to extensive critique and noncompliance. How does the emergence of non-Homo-
intelligences affect this discussion? At a minimum, it is becoming rapidly difficult to
hide behind vague intuition for ethical decisions—“I know it when I see it” (U.S.
Supreme Court Justice Potter Stewart, 1964) or the “wisdom of repugnance” (aka “yuck
factor,” Leon Kass, 1997), or vague appeals to “common sense.” As we have to deal
with minds alien to us, sometimes quite literal from our viewpoint, we need to be
explicit—yea, even algorithmic.

Self-driving cars, drones, stock-market transactions, NSA searches, et cetera,
require rapid, pre-approved decision making. We may gain insights into many aspects of
ethics that we have been trying to pin down and explain for centuries. The challenges
have included conflicting priorities, as well as engrained biological, sociological, and
semi-logical cognitive biases. Notably far from consensus in universal dogmas about
human rights are notions of privacy and dignity, even though these influence many laws
and guidelines.

Humans might want the right to march in to read (and change) the minds of
computers to see why they’re making decisions at odds with our (Homo) instincts. Is it
not fair for machines to ask the same of us? We note the growth of movements toward
transparency in potential financial conflicts; “open-source” software, hardware, and
wetware; the Fair Access to Science and Technology Research Act (FASTR); and the
Open Humans Foundation.

In his 1976 book Computer Power and Human Reason, Joseph Weizenbaum
argued that machines should not replace Homo in situations requiring respect, dignity, or
care, while others (author Pamela McCorduck and computer scientists like John
McCarthy and Bill Hibbard) replied that machines can be more impartial, calm, and
consistent and less abusive or mischievous than people in such positions.

Equality
What did the thirty-three-year-old Thomas Jefferson mean in 1776 when he wrote, “We
hold these Truths to be self-evident, that all Men are created equal, that they are endowed

169

HOUSE_OVERSIGHT_016389
