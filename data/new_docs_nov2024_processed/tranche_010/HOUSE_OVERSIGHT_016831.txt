Computer scientist Stuart Russell, along with Elon Musk, Stephen Hawking, Max
Tegmark, and numerous others, has insisted that attention be paid to the potential
dangers in creating an intelligence on the superhuman (or even the human) level—an
AGI, or artificial general intelligence, whose programmed purposes may not necessarily
align with our own.

His early work was on understanding the notion of “bounded optimality” as a
formal definition of intelligence that you can work on. He developed the technique of
rational meta-reasoning, “which is, roughly speaking, that you do the computations that
you expect to improve the quality of your ultimate decision as quickly as possible.” He
has also worked on the unification of probability theory and first-order logic—resulting
in a new and far more effective monitoring system for the Comprehensive Nuclear Test
Ban Treaty—and on the problem of decision making over long timescales (his
presentations on the latter topic are usually titled, “Life: Play and Win in 20 trillion
moves”’).

He is very concerned with the continuing development of autonomous weapons,
such as lethal micro-drones, which are potentially scalable into weapons of mass
destruction. He drafted the letter from forty of the world’s leading AI researchers to
President Obama which resulted in high-level national-security meetings.

His current work centers on the creation of what he calls “provably beneficial”
AI. He wants to ensure AI safety by “imbuing systems with explicit uncertainty” about
the objectives of their human programmers, an approach that would amount to a fairly
radical reordering of current AI research.

Stuart is also on the radar of anyone who has taken a course in computer science
in the last twenty-odd years. He is co-author of “the” definitive AI textbook, with an
estimated 5-million-plus English-language readers.

28

HOUSE_OVERSIGHT_016831
