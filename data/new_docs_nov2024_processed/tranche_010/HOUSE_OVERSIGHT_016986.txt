When we consider the future of AI, we need to think about the goals. That’s what
humans contribute; that’s what our civilization contributes. The execution of those goals
is what we can increasingly automate. What will the future of humans be in such a
world? What will there be for them to do? One of my projects has been to understand
the evolution of human purposes over time. Today we’ve got all kinds of purposes. If
you look back a thousand years, people’s goals were quite different: How do I get my
food? How do I keep myself safe? In the modern Western world, for the most part you
don’t spend a large fraction of your life thinking about those purposes. From the point of
view of a thousand years ago, some of the goals people have today would seem utterly
bizarre—for example, like exercising on a treadmill. A thousand years ago that would
sound like a crazy thing to do.

What will people be doing in the future? A lot of purposes we have today are
generated by scarcity of one kind or another. There are scarce resources in the world.
People want to get more of something. Time itself is scarce in our lives. Eventually,
those forms of scarcity will disappear. The most dramatic discontinuity will surely be
when we achieve effective human immortality. Whether this will be achieved
biologically or digitally isn’t clear, but inevitably it will be achieved. Many of our
current goals are driven in part by our mortality: “I’m only going to live a certain time, so
I'd better get this or that done.” And what happens when most of our goals are executed
automatically? We won’t have the kinds of motivations we have today. One question I’d
like an answer for is, What do the derivatives of humans in the future end up choosing to
do with themselves? One of the potential bad outcomes is that they just play video games
all the time.

The term “artificial intelligence” is evolving, in its use in technical language. These
days, AI is very popular, and people have some idea of what it means. Back when
computers were being developed, in the 1940s and 1950s, the typical title of a book or a
magazine article about computers was “Giant Electronic Brains.” The idea was that just
as bulldozers and steam engines and so on automated mechanical work, computers would
automate intellectual work. That promise turned out to be harder to fulfill than many
people expected. There was, at first, a great deal of optimism; a lot of government
money got spent on such efforts in the early 1960s. They basically just didn’t work.

There are a lot of amusing science-fiction-ish portrayals of computers in the
movies of that time. There’s a cute one called Desk Set, which is about an IBM-type
computer being installed in a broadcasting company and putting everybody out of a job.
It’s cute because the computer gets asked a bunch of reference-library questions. When
my colleagues and I were building Wolfram|Alpha, one of the ideas we had was to get it
to answer all of those reference-library questions from Desk Set. By 2009, it could
answer them all.

In 1943, Warren McCulloch and Walter Pitts came up with a model for how
brains conceptually, formally, might work—an artificial neural network. They saw that
their brainlike model would do computations in the same way as Turing Machines. From
their work, it emerged that we could make brainlike neural networks that would act as
general computers. And in fact, the practical work done by the ENIAC folks and John

183

HOUSE_OVERSIGHT_016986
