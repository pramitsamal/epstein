10.5 How Might the Mind-World Correspondence Principle Be Useful? 181

That is, a little more loosely: the hypothesis is that, for intelligence to occur, there has to be a
natural correspondence between the transition-sequences of world-states and the corresponding
transition-sequences of mind-states, at least in the cases of transition-sequences leading to
relevant goals.

We suspect that a variant of the above proposition can be formally proved, using the definition
of general intelligence presented in Chapter 7. The proof of a theorem corresponding to the
above would certainly constitute an interesting start toward a general formal theory of general
intelligence. Note that proving anything of this nature would require some attention to the
time-scale-dependence of the link weights in the transition graphs involved.

A formally proved variant of the above proposition would be in short, a MIND-WORLD
CORRESPONDENCE THEOREM.

Recall that at the start of the chapter, we expressed the same idea as:

MIND-WORLD CORRESPONDENCE-PRINCIPLE

For a mind to work intelligently toward certain goals in a certain world, there should be a
nice mapping from goal-directed sequences of world-states into sequences of mind-states, where
nice means that a world-state-sequence W composed of two parts W, and Ws, gets mapped
into a mind-state-sequence M composed of two corresponding parts MM, and Mg.

That is a reasonable gloss of the principle, but it’s clunkier and less accurate, than the
statement in terms of functors and path transfer functions, because it tries to use only common-
language vocabulary, which doesn’t really contain all the needed concepts.

10.5 How Might the Mind-World Correspondence Principle Be
Useful?

Suppose one believes the Mind-World Correspondence Principle as laid out above so what?

Our hope, obviously, is that the principle could be useful in actually figuring out how to
architect intelligent systems biased toward particular sorts of environment. And of course, this
is said with the understanding that any finite intelligence must be biased toward some sorts of
environment.

Relatedly, given a specific AGI design (such as CogPrime), one could use the principle to
figure out which environments it would be best suited for. Or one could figure out how to
adjust the particulars of the design, to maximize the system’s intelligence in the environments
of interest.

One next step in developing this network of ideas, aside from (and potentially building on)
full formalization of the principle, would be an exploration of real-world environments in terms
of transition graphs. What properties do the transition graphs induced from the real world
have?

One such property, we suggest, is successive refinement. Often the path toward a goal in-
volves first gaining an approximate understanding of a situation, then a slightly more accurate
understanding, and so forth — until finally one has achieved a detailed enough understanding to
actually achieve the goal. This would be represented by a world-path whose nodes are state-sets
involving the gathering of progressively more detailed information.

HOUSE_OVERSIGHT_013097
