4.3 Emergentist Cognitive Architectures 65

4.3 Emergentist Cognitive Architectures

Another species of cognitive architecture expects abstract symbolic processing to emerge from
lower-level “subsymbolic” dynamics, which sometimes (but not always) are designed to simu-
late neural networks or other aspects of human brain function. These architectures are typically
strong at recognizing patterns in high-dimensional data, reinforcement learning and associative
memory; but no one has yet shown how to achieve high-level functions such as abstract reason-
ing or complex language processing using a purely subsymbolic approach. A few of the more
important subsymbolic, emergentist cognitive architectures are:

e DeSTIN [ARK09a, ARCO9], which is part of CogPrime, may also be considered as an
autonomous AGI architecture, in which case it is emergentist and contains mechanisms
to encourage language, high-level reasoning and other abstract aspects of intelligent to
emerge from hierarchical pattern recognition and related self-organizing network dynamics.
In CogPrime DeSTIN is used as part of a hybrid architecture, which greatly reduces the
reliance on DeSTIN’s emergent properties.

e Hierarchical Temporal Memory (HTM) [I06] is a hierarchical temporal pattern
recognition architecture, presented as both an AI approach and a model of the cortex. So
far it has been used exclusively for vision processing and we will discuss its shortcomings
later in the context of our treatment of DeSTIN.

e SAL [JL08], based on the earlier and related IBCA (Integrated Biologically-based Cog-
nitive Architecture) is a large-scale emergent architecture that seeks to model distributed
information processing in the brain, especially the posterior and frontal cortex and the
hippocampus. So far the architectures in this lineage have been used to simulate various
human psychological and psycholinguistic behaviors, but haven’t been shown to give rise to
higher-level behaviors like reasoning or subgoaling.

e NOMAD (Neurally Organized Mobile Adaptive Device) automata and its successors
[KE06] are based on Edelman’s “Neural Darwinism” model of the brain, and feature large
numbers of simulated neurons evolving by natural selection into configurations that carry
out sensorimotor and categorization tasks. The emergence of higher-level cognition from
this approach seems rather unlikely.

e Ben Kuipers and his colleagues [MK07, MIX08, MIXO09]have pursued an extremely innovative
research program which combines qualitative reasoning and reinforcement learning to enable
an intelligent agent to learn how to act, perceive and model the world. Kuipers’ notion of
“bootstrap learning” involves allowing the robot to learn almost everything about its world,
including for instance the structure of 3D space and other things that humans and other
animals obtain via their genetic endowments. Compared to Kuipers’ approach, CogPrime
falls in line with most other approaches which provide more “hard-wired” structure, following
the analogy to biological organisms that are born with more innate biases.

There is also a set of emergentist architectures focused specifically on developmental robotics,
which we will review below in a separate subsection, as all of these share certain common
characteristics.

Our general perspective on the emergentist approach is that it is philosophically correct
but currently pragmatically inadequate. Eventually, some emergentist approach could surely
succeed at giving rise to humanlike general intelligence — the human brain, after all, is plainly
an emergentist system. However, we currently lack understanding of how the brain gives rise
to abstract reasoning and complex language, and none of the existing emergentist systems

HOUSE_OVERSIGHT_012981
