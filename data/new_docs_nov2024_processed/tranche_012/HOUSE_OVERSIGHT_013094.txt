178 10 A Mind-World Correspondence Principle

10.2 What Might a General Theory of General Intelligence Look
Like?

It’s not clear, at this point, what a real general theory of general intelligence would look like
— but one tantalizing possibility is that it might confront the two questions:

e How does one design a world to foster the development of a certain sort of mind?
e How does one design a mind to match the particular challenges posed by a certain sort of
world?

One way to achieve this would be to create a theory that, given a description of an environment
and some associated goals, would output a description of the structure and dynamics that a
system should possess to be intelligent in that environment relative to those goals, using limited
computational resources.

Such a theory would serve a different purpose from the mathematical theory of universal
intelligence developed by Marcus Hutter [Hut05] and others. For all its beauty and theoreti-
cal power, that approach currently gives it useful conclusions only about general intelligences
with infinite or infeasibly massive computational resources. On the other hand, the approach
suggested here is aimed toward creation of a theory of real-world general intelligences utilizing
realistic amounts of computational power, but still possessing general intelligence comparable
to human beings or greater.

This reflects a vision of intelligence as largely concerned with adaptation to particular classes
of environments and goals. This may seem contradictory to the notion of general intelligence,
but I think it actually embodies a realistic understanding of general intelligence. Maximally
general intelligence is not pragmatically feasible; it could only be achieved using infinite com-
putational resources [ITut05]. Real-world systems are inevitably limited in the intelligence they
can display in any real situation, because real situations involve finite resources, including finite
amounts of time. One may say that, in principle, a certain system could solve any problem
given enough resources and time but, even when this is true, it’s not necessarily the most in-
teresting way to look at the system’s intelligence. It may be more important to look at what a
system can do given the resources at its disposal in reality. And this perspective leads one to
ask questions like the ones posed above: which bounded-resources systems are well-disposed to
display intelligence in which classes of situations?

As noted in Chapter 7 above, one can assess the generality of a system’s intelligence via
looking at the entropy of the class of situations across which it displays a high level of intelligence
(where “high” is measured relative to its total level of intelligence across all situations). A system
with a high generality of intelligence will tend to be roughly equally intelligent across a wide
variety of situations; whereas a system with lower generality of intelligence will tend to be much
more intelligent in a small subclass of situations, than in any other. The definitions given above
embody this notion in a formal and quantitative way.

If one wishes to create a general theory of general intelligence according to this sort of
perspective, the main question then becomes how to represent goals/environments and systems
in such a way as to render transparent the natural correspondence between the specifics of the
former and the latter, in the context of resource-bounded intelligence. This is the business of
the next section.

HOUSE_OVERSIGHT_013094
