3.5 Perspectives on Machine Consciousness 51

e do so in such a way as to lead to self and attentional focus as emergent structures that serve
as approximate attractors of this dynamic, over time periods that are long relative to the
basic “cognitive cycle time” of the system’s forward-analysis dynamics

To prove the truth of a hypothesis of this nature would seem to require mathematics fairly
far beyond anything that currently exists. Nonetheless, however, we feel it is important to
formulate and discuss such hypotheses, so as to point the way for future investigations both
theoretical and pragmatic.

3.5 Perspectives on Machine Consciousness

Finally, we can’t let a chapter on philosophy — even a brief one — end without some discussion
of the thorniest topic in the philosophy of mind: consciousness. Rather than seeking to resolve
or comprehensively review this most delicate issue, we will restrict ourselves to giving it in
Appendix ?? an overview of many of the common views on the subject; and here in the main text
discussing the relationship between consciousness theory and patternist philosophy of cognition,
the practical work of designing and building AGI.

One fairly concrete idea about consciousness, that relates closely to certain aspects of the
CogPrime design, is that the subjective experience of being conscious of some entity X, is corre-
lated with the presence of a very intense pattern in one’s overall mind-state, corresponding to X.
This simple idea is also the essence of neuroscientist Susan Greenfield’s theory of consciousness
[GreO1] (but in her theory, overall mind-state” is replaced with brain-state), and has much
deeper historical roots in philosophy of mind which we shall not venture to unravel here.

This observation relates to the idea of moving bubbles of awareness in intelligent systems.
If an intelligent system consists of multiple processing or data elements, and during each (suf-
ficiently long) interval of time some of these elements get much more attention than others,
then one may view the system as having a certain attentional focus during each interval. The
attentional focus is itself a significant pattern in the system (the pattern being these elements
habitually get more processor and memory, roughly speaking). As the attentional focus shifts
over time one has a moving bubble of pattern which then corresponds experientially to a
moving bubble of awareness.

This notion of a moving bubble of awareness ties in very closely to global workspace
theory [Baa97] (briefly mentioned above), a cognitive theory that has broad support from
neuroscience and cognitive science and has also served as the motivation for Stan Franklin’s
LIDA AI system [BF09], to be discussed in Chapter ??. The global workspace theory views the
mind as consisting of a large population of small, specialized processes — a society of agents.
These agents organize themselves into coalitions, and coalitions that are relevant to contextually
novel phenomena, or contextually important goals, are pulled into the global workspace (which
is identified with consciousness). This workspace broadcasts the message of the coalition to al
the unconscious agents, and recruits other agents into consciousness. Various sorts of contexts
— e.g. goal contexts, perceptual contexts, conceptual contexts and cultural contexts — play a
role in determining which coalitions are relevant, and form the unconscious background o
the conscious global workspace. New perceptions are often, but not necessarily, pushed into the
workspace. Some of the agents in the global workspace are concerned with action selection, i.e.
with controlling and passing parameters to a population of possible actions. The contents o
the workspace at any given time have a certain cohesiveness and interdependency, the so-called

HOUSE_OVERSIGHT_012967
