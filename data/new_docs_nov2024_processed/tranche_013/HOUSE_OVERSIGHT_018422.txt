of ELIZA, the theoretical mathematician Doron Zeilberger now names his computer
as a co-author of his papers. He calls it Shalosh B. Ekhad, a play on the Hebrew name
of his IBM 3B1.) 258

The AI systems designer Roger Grosse has named two paths to this sort of wired
sensibility: “Predictive Learning” and “Representational Learning”.25° That first
approach is what Maes’s movie machine pusued. The computer is simply checking
what it encounters against a database. It teaches itself to predict based on what has
been seen before. This sort of knowledge begins with massive amounts of data and
then hunts for patterns, tests their reliability, and improves by mapping quirks and
similarities. Google engineers have a device that can gaze into a human eye and spot
signs of impending optical failure. Is the machine smarter than your
ophthalmologist? Hard to know, but let’s just say this: It has seen, studied and
compared millions of eyes to find patterns that nearly perfectly predict a diagnosis.
It can review in seconds more cases than your doctor will see in a lifetime - let alone
recall and compare at sub-millimeter accuracy. Fast, thorough predictive algorithms
make what might once have been regarded as AI disappear. The machine isn’t all
that wise; it just knows a lot.

On the other path, the one of “representational learning” the machine uses a self-
sketched image of the world, a “representation.” Computers using predictive
methods to recognize 10,000 numbers pulled from a database of scrawled hand
writing now identify 90 percent of the images. Self-trained machines, however, line
up each scanned pixel against a representation of the very idea of writing. They
screen millions of pictures with nary a mistake. Faces, disease markers, obscure
sounds - all these become scrutable not because the machines have been told what
to look for, but because they’ve sort of figured it out themselves. The Al is actually
starting to think, much as you or | might, first by building up a picture of the world
and then applying it, much as a child might build comprehension of traffic rules just
by watching Mom driving every day.

With this representation finished, these nearly alive “thinking” meshes navigate by
themselves. You can see already the competition lingering here - who can build the
most sensitive model of the world? You? A machine? Even today basic versions of
representational Als can study a map and name the most important roads. They can
predict cracks in computer networks days before a fault. These programs take
longer to train. They are harder to program - and they demand almost unimaginable
amounts of computing power - but what emerges is a subtle, lively kind of insight. A
machine with a representational understanding of Mozart's 41 symphonies can
write you an extremely convincing 424 - or, if you wish, an even earlier First
Symphony based on what it knows about his evolution as a composer. It can do it
again and again. In seconds. The basic attitude of these researchers behind this
technology runs, they confess, like this: Mozart was a fantastic composer. If he wrote

258 He calls it: See Nielsen
259 The AI systems designer: Roger Grosse, “Predictive Learning vs.
Representational Learning”, Building Intelligent Probabilistic Systems: 2013

190

HOUSE_OVERSIGHT_018422
