48 3 A Patternist Philosophy of Mind

others but with a few original twists. From a CogPrime perspective, its use has been to guide
the design process, to provide a grounding for what otherwise would have been fairly arbitrary
choices.

3.4.4.1 Self

Another high-level intelligent system pattern mentioned above is the “self”, which we here will tie
in with analysis and synthesis processes. The term “self” as used here refers to the “phenomenal
self” [Met04] or “selfmodel”. That is, the self is the model that a system builds internally,
reflecting the patterns observed in the (external and internal) world that directly pertain to
the system itself. As is well known in everyday human life, selfmodels need not be completely
accurate to be useful; and in the presence of certain psychological factors, a more accurate
self-model may not necessarily be advantageous. But a self-model that is too badly inaccurate
will lead to a badly-functioning system that is unable to effectively act toward the achievement
of its own goals.

The value of a self-model for any intelligent system carrying out embodied agentive cognition
is obvious. And beyond this, another primary use of the self is as a foundation for metaphors
and analogies in various domains. Patterns recognized pertaining to the self are analogically
extended to other entities. In some cases this leads to conceptual pathologies, such as the an-
thropomorphization of trees, rocks and other such objects that one sees in some precivilized
cultures. But in other cases this kind of analogy leads to robust sorts of reasoning - for instance,
in reading Lakoff and Nunez’s [LN00] intriguing explorations of the cognitive foundations of
mathematics, it is pretty easy to see that most of the metaphors on which they hypothesize
mathematics to be based, are grounded in the mind’s conceptualization of itself as a spatiotem-
porally embedded entity, which in turn is predicated on the mind’s having a conceptualization
of itself (a self) in the first place.

A self-model can in many cases form a self-fulfilling prophecy (to make an obvious double-

entendre’!). Actions are generated based on one’s model of what sorts of actions one can and/or
should take; and the results of these actions are then incorporated into one’s self-model. If a
self-model proves a generally bad guide to action selection, this may never be discovered, unless
said self-model includes the knowledge that semi-random experimentation is often useful.
In what sense, then, may it be said that self is an attractor of iterated analysis? Analysis
infers the self from observations of system behavior. The system asks: What kind of system
might I be, in order to give rise to these behaviors that I observe myself carrying out? Based
on asking itself this question, it constructs a model of itself, i.e. it constructs a self. Then, this
self guides the system’s behavior: it builds new logical relationships its self-model and various
other entities, in order to guide its future actions oriented toward achieving its goals. Based on
the behaviors newly induced via this constructive, forward-synthesis activity, the system may
then engage in analysis again and ask: What must I be now, in order to have carried out these
new actions? And so on.

Our hypothesis is that after repeated iterations of this sort, in infancy, finally during early
childhood a kind of selfreinforcing attractor occurs, and we have a selfmodel that is resilient
and doesn’t change dramatically when new instances of action- or explanation-generation occur.
This is not strictly a mathematical attractor, though, because over a long period of time the self
may well shift significantly. But, for a mature self, many hundreds of thousands or millions of
forward-analysis cycles may occur before the self-model is dramatically modified. For relatively

HOUSE_OVERSIGHT_012964
