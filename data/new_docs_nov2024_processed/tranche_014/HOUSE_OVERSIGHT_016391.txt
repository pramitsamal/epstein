If robots don’t have exactly the same consciousness as humans, then this is used
as an excuse to give them different rights, analogous to arguments that other tribes or
races are less than human. Do robots already show free will? Are they already self-
conscious? The robots Qbo have passed the “mirror test” for self-recognition and the
robots NAO have passed a related test of recognizing their own voice and inferring their
internal state of being, mute or not.

For free will, we have algorithms that are neither fully deterministic nor random
but aimed at nearly optimal probabilistic decision making. One could argue that this is a
practical Darwinian consequence of game theory. For many (not all) games/problems, if
we’re totally predictable or totally random, then we tend to lose.

What is the appeal of free will anyway? Historically it gave us a way to assign
blame in the context of reward and punishment on Earth or in the afterlife. The goals of
punishment might include nudging the priorities of the individual to assist the survival of
the species. In extreme cases, this could include imprisonment or other restrictions, if
Skinnerian positive/negative reinforcement is inadequate to protect society. Clearly, such
tools can apply to free will, seen broadly—to any machine whose behavior we’d like to
manage.

We could argue as to whether the robot actually experiences subjective qualia for
free will or self-consciousness, but the same applies to evaluating a human. How do we
know that a sociopath, a coma patient, a person with Williams syndrome, or a baby has
the same free will or self-consciousness as our own? And what does it matter,
practically? If humans (of any sort) convincingly claim to experience consciousness,
pain, faith, happiness, ambition, and/or utility to society, should we deny them rights
because their hypothetical qualia are hypothetically different from ours?

The sharp red lines of prohibition, over which we supposedly will never step,
increasingly seem to be short-lived and not sensible. The line between human and
machines blurs, both because machines become more humanlike and humans become
more machine-like—not only since we increasingly blindly follow GPS scripts, reflex
tweets, and carefully crafted marketing, but also as we digest ever more insights into our
brain and genetic programming mechanisms. The NIH BRAIN Initiative is developing
innovative technologies and using these to map out the connections and activity of mental
circuitry so as to improve electronic and synthetic neurobiological ware.

Various red lines depend on genetic exceptionalism, in which genetics 1s
considered permanently heritable (although it is provably reversible), whereas exempt
(and lethal) technologies, like cars, are for all intents and purposes irreversible due to
social and economic forces. Within genetics, a red line makes us ban or avoid genetically
modified foods but embrace genetically modified bacteria making insulin, or genetically
modified humans—witness mitochondrial therapies approved in Europe for human adults
and embryos.

The line for germline manipulation seems less sensible than the usual, practical
line drawn at safety and efficacy. Marriages of two healthy carriers of the same genetic
disease have a choice between no child of their own, 25-percent loss of embryos via
abortion (spontaneous or induced), 80-percent loss via in-vitro fertilization, or potential
zero-percent embryo loss via sperm (germline) engineering. It seems premature to
declare this last option unlikely.

171

HOUSE_OVERSIGHT_016391
