system that could, in a very limited sense, converse. The computer would take typed
input from a user and then, based on what it understood, ask a question back to
continue the conversation. The approach was borrowed from the psychological
theories of Carl Rogers, an American therapist who believed the best way to talk to
patients was with open ended, careful questions. Weizenbaum developed two
programs. The first was called DOCTOR, a script that determined what the computer
might say. The natural language processor responsible for carrying on the human
side of the conversation he called ELIZA, after the heroine from Pygmalion, a poor
cockney girl who is trained by a phonetics professor to pass as a duchess.

Here is a discussion between ELIZA and a user that Weizenbaum recorded in 1965:
Patient: “Men are all alike.”

ELIZA: “IN WHAT WAY?”

Patient: “They’re always bugging us about something or other.”

ELIZA: “CAN YOU THINK OF A SPECIFIC EXAMPLE?”

Patient: “Well, my boyfriend made me come here.”

ELIZA: “YOUR BOYFRIEND MADE YOU COME HERE?”

Patient: “He says | am depressed most of the time.”

ELIZA: “I AM SORRY TO HEAR YOU ARE DEPRESSED.”

Patient: “It’s true, I’m depressed most of the time.”

ELIZA: “DO YOU THINK COMING HERE WILL HELP YOU TO NOT BE UNHAPPY?”

Patient: “I need some help, that much seems certain.”

Weizenbaum’s program quickly became famous around MIT. (The joke was that it
was a better conversationalist than most of the awkward shoegazers studying at the
Cambridge campus.) ELIZA gave users a chance to have a taste of a machine with
something like a mind of its own. The program spread to other campuses, to
different research institutions, and with every step of its success, Weizenbaum
found himself more distressed. He summarized his worries in his 1972 masterpiece
Computer Science and Human Reason. What troubled him was not ELIZA, but her
users, the humans. Even when they were professional psychologists, many of them
quickly considered it reasonable to think that one day the work of diagnosis and
counseling might be turned over to machines. This felt like a natural next step in the
ceaseless progress they were used to in their lives. Better refrigerators, stronger
seat belts, faster jet planes, more plastic - why nota computer doing therapy? It

121

HOUSE_OVERSIGHT_018353
