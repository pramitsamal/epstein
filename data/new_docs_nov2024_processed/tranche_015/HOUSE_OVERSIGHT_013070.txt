154 8 Cognitive Synergy

'

Representation-Building

\

}

| Random Sampling |
; + I
\ |

\

\ |
Scorins

; &

Optimization

!

Fig. 8.4: High-Level Control Flow of MOSES Algorithm

For example, suppose an CogPrime -controlled robot is trying to learn to play the game
of “tag. (Le. a multi-agent game in which one agent is specially labeled it, and runs after
the other player agents, trying to touch them. Once another agent is touched, it becomes the
new it and the previous it becomes just another player agent.) Then its context C is that
others are trying to play a game they call “tag” with it; and we may assume its goals are to
please them and itself, and that it has figured out that in order to achieve this goal it should
learn some procedure to follow when interacting with others who have said they are playing
“tag.” In this case a potential tag-playing procedure might contain nodes for physical actions
like step forward(speed s), as well as control flow nodes containing operators like ifelse
(for instance, there would probably be a conditional telling the robot to do something different
depending on whether someone seems to be chasing it). Each of these program tree nodes would
have an appropriate knob assigned to it. And the scoring function would evaluate a procedure
P in terms of how successfully the robot played tag when controlling its behaviors according to
P (noting that it may also be using other control procedures concurrently with P). It’s worth
noting here that evaluating the scoring function in this case involves some inference already,
because in order to tell if it is playing tag successfully, in a real-world context, it must watch
and understand the behavior of the other players.

MOSES follows the high-level control flow depicted in Figure 8.4, which corresponds to the
following process for evolving a metapopulation of “demes“ of programs (each deme being a set
of relatively similar programs, forming a sort of island in program space):

1. Construct an initial set of knobs based on some prior (e.g., based on an empty program;
or more interestingly, using prior knowledge supplied by PLN inference based on the
system’s memory) and use it to generate an initial random sampling of programs. Add this
deme to the metapopulation.

2. Select a deme from the metapopulation and update its sample, as follows:

HOUSE_OVERSIGHT_013070
