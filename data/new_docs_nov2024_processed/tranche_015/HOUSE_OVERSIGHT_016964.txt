The algorist view has gained strength. Anne Milgram served as Attorney General
of the State of New Jersey from 2007 to 2010. When she took office, she wanted to
know who the state was arresting, charging, and jailing, and for what crimes. At the
time, she reports in a later TED Talk, she could find almost no data or analytics. By
imposing statistical prediction, she continues, law enforcement in Camden during her
tenure was able to reduce murders by 41 percent, saving thirty-seven lives, while
dropping the total crime rate by 26 percent. After joining the Arnold Foundation as its
vice president for criminal justice, she established a team of data scientists and
statisticians to create a risk-assessment tool; fundamentally, she construed the team’s
mission as deciding how to put “dangerous people” in jail while releasing the non-
dangerous. “The reason for this,” Milgram contended, “is the way we make decisions.
Judges have the best intentions when they make these decisions about risk, but they’re
making them subjectively. They’re like the baseball scouts twenty years ago who were
using their instinct and their experience to try to decide what risk someone poses.
They’re being subjective, and we know what happens with subjective decision making,
which is that we are often wrong.” Her team established nine-hundred-plus risk factors,
of which nine were most predictive. The questions, the most urgent questions, for the
team were: Will a person commit a new crime? Will that person commit a violent act?
Will someone come back to court? We need, concluded Milgram, an “objective measure
of risk” that should be inflected by judges’ judgment. We know the algorithmic
statistical process works. That, she says, is “why Google is Google” and why moneyball
wins games.*?

Algorists have triumphed. We have grown accustomed to the idea that protocols
and data can and should guide us in everyday action, from reminders about where we
probably want to go next, to the likely occurrence of crime. By now, according to the
literature, the legal, ethical, formal, and economic dimensions of algorithms are all quasi-
infinite. I’d like to focus on one particular siren song of the algorithm: its promise of
objectivity.

Scientific objectivity has a history. That might seem surprising. Isn’t the
notion—expressed above by the Minnesota psychologists—right? Isn’t objectivity co-
extensive with science itself? Here it’s worth stepping back to reflect on all the epistemic
virtues we might value in scientific work. Quantification seems like a good thing to
have; so, too, do prediction, explanation, unification, precision, accuracy, certainty, and
pedagogical utility. In the best of all possible worlds these epistemic virtues would all
pull in the same direction. But they do not—not any more than our ethical virtues
necessarily coincide. Rewarding people according to their need may very well conflict
with rewarding people according to their ability. Equality, fairness, meritocracy—ethics,
in a sense, is all about the adjudication of conflicting goods. Too often we forget that this
conflict exists in science, too. Design an instrument to be as sensitive as possible and it
often fluctuates wildly, making repetition of a measurement impossible.

“Scientific objectivity” entered both the practice and the nomenclature of science
after the first third of the 19th century. One sees this clearly in the scientific atlases that
provided scientists with the basic objects of their specialty: There were (and are) atlases
of the hand, atlases of the skull, atlases of clouds, crystals, flowers, bubble-chamber
pictures, nuclear emulsions, and diseases of the eye. In the 18th century, it was obvious

‘43 TED Talk, January 2014, https://www.ted.com/speakers/anne_milgram.

161

HOUSE_OVERSIGHT_016964
