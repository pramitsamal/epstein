Steven Pinker: Tech Prophecy and the Underappreciated Causal Power of Ideas
There is no law of complex systems that says that intelligent agents must turn into
ruthless megalomaniacs.

David Deutsch: Beyond Reward and Punishment
Misconceptions about human thinking and human origins are causing corresponding
misconceptions about AGI and how it might be created.

Tom Griffiths: The Artificial Use of Human Beings
Automated intelligent systems that will make good inferences about what people want
must have good generative models for human behavior.

Anca Dragan: Putting the Human into the AI Equation
In the real world, an AI must interact with people and reason about them. People will
have to formally enter the AI problem definition somewhere.

Chris Anderson: Gradient Descent

Just because Al systems sometimes end up in local minima, don’t conclude that this
makes them any less like life. Humans—indeed, probably all life-forms—are often stuck
in local minima.

David Kaiser: “Information” for Wiener, for Shannon, and for Us

Many of the central arguments in The Human Use of Human Beings seem closer to the
19th century than the 21st. Wiener seems not to have fully embraced Shannon’s notion of
information as consisting of irreducible, meaning-free bits.

Neil Gershenfeld: Scaling
Although machine making and machine thinking might appear to be unrelated trends,
they lie in each other’s futures.

W. Daniel Hillis: The First Machine Intelligences

Hybrid superintelligences such as nation states and corporations have their own
emergent goals and their actions are not always aligned to the interests of the people
who created them.

Venki Ramakrishnan: Will Computers Become Our Overlords?
Our fears about AI reflect the belief that our intelligence is what makes us special.

Alex “Sandy” Pentland: The Human Strategy

How can we make a good human-artificial ecosystem, something that’s not a machine
society but a cyberculture in which we can all live as humans—a culture with a human
feel to it?

HOUSE_OVERSIGHT_016810
