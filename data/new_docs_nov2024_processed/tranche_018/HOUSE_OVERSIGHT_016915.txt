something to say! Heaven save us likewise from the mathematical papers which are
correct and elegant but without body or spirit.” Wiener’s treatment of “information”
sounded more like Matthew Arnold in 1869°? than Claude Shannon in 1948—more
“body and spirit” than “bit.” Wiener shared Arnold’s Romantic view of the “content
producer” as well. “Properly speaking the artist, the writer, and the scientist should be
moved by such an irresistible impulse to create that, even if they were not being paid for
their work, they would be willing to pay to get the chance to do it.” L’art pour Iart, that
19th-century cry: Artists should suffer for their work; the quest for meaningful expression
should always trump lucre.

To Wiener, this was the proper measure of “information”: body, spirit, aspiration,
expression. Yet to argue against its commodification, Wiener reverted again to
Shannon’s mathematics of information-as-entropy.

Flash forward to our day. In many ways, Wiener has been proved right. His vision of
networked feedback loops driven by machine-to-machine communication has become a
mundane feature of everyday life. From the earliest stirrings of the Internet Age,
moreover, digital piracy has upended the view that “information”—in the form of songs,
movies, books, or code—could remain contained. Put up a paywall here, and the content
will diffuse over there, all so much informational entropy that cannot be conserved.

On the other hand, enormous multinational corporations—some of the largest and
most profitable in the world—now routinely disprove Wiener’s contention that
“information” cannot be stockpiled or monetized. Ironically, the “information” they
trade in is closer to Shannon’s definition than Wiener’s, Shannon’s mathematical proofs
notwithstanding.

While Google Books may help circulate hundreds of thousands of works of
literature for free, Google itself—like Facebook, Amazon, Twitter, and their many
imitators—has commandeered a baser form of “information” and exploited it for
extraordinary profit. Petabytes of Shannon-like information—a seemingly meaningless
stream of clicks, “likes,” and retweets, collected from virtually every person who has ever
touched a networked computer—are sifted through proprietary “deep-learning”
algorithms to micro-target everything from the advertisements we see to the news stories
(fake or otherwise) we encounter while browsing the Web.

Back in the early 1950s, Wiener had proposed that researchers study the
structures and limitations of ants—in contrast to humans—so that machines might one
day achieve the “almost indefinite intellectual expansion” that people (rather than insects)
can attain. He found solace in the notion that machines could come to dominate us only
“in the last stages of increasing entropy,” when “the statistical differences among
individuals are nil.” Today’s data-mining algorithms turn Wiener’s approach on its head.
They produce profit by exploiting our reptilian brains rather than imitating our cerebral
cortexes, harvesting information from all our late-night, blog-addled, pleasure-seeking
clickstreams—leveraging precisely the tiny, residual “statistical differences among
individuals.”

32 Matthew Amold, Culture and Anarchy, Jane Garnett, ed. (Oxford, U.K.: Oxford University Press, 2006).

112

HOUSE_OVERSIGHT_016915
