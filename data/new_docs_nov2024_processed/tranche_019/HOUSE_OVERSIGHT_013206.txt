290 16 AGI Preschool

and set it loose in the everyday human world; but of course, this isn’t feasible given the current
state of development of robotics technology. So one must seek approximations. Toward this end
we have embodied OpenCogPrime in non-player characters in video game style virtual worlds,
and carried out preliminary experiments embodying OpenCogPrime in humanoid robots. These
are reasonably good options but they have limitations and lead to subtle choices: what kind of
game characters and game worlds, what kind of robot environments, etc.?

One conclusion we have come to, based largely on the considerations in Chapter 11 on
development and Chapter 9 on the importance of environment, is that it may make sense to
embed early-stage proto-AGI and AGI systems in environments reminiscent of those used for
teaching young human children. In this chapter we will explore this approach in some detail:
emulation, in either physical reality or an multiuser online virtual world, of an environment
similar to preschools used in early human childhood education. Complete specification of an
“AGI Preschool” would require much more than a brief chapter; our goal here is to sketch the
idea in broad outline, and give a few examples of the types of opportunities such an environment
would afford for instruction, spontaneous learning and formal and informal evaluation of certain
sorts of early-stage AGI systems.

The material in this chapter will pop up fairly often later in the book. The AGI Preschool
context will serve, throughout the following chapters, as a source of concrete examples of the
various algorithms and structures. But it’s not proposed merely as an expository tool; we are
making the very serious proposal that sending AGI systems to a virtual or robotic preschool is
an excellent way — perhaps the best way — to foster the development of human-level human-like
AGI.

16.1.1 Contrast to Standard AI Evaluation Methodologies

The reader steeped in the current AI literature may wonder why it’s necessary to introduce a
new methodology and environment for evaluating AGI systems. There are already very many
different ways of evaluating AI systems out there ... do we really need another?

Certainly, the AI field has inspired many competitions, each of which tests some particu-
lar type or aspect of intelligent behavior. Examples include robot competitions, tournaments of
computer chess, poker, backgammon and so forth at computer olympiads, trading-agent compe-
tition, language and reasoning competitions like the Pascal Textual Entailment Challenge, and
so on. In addition to these, there are many standard domains and problems used in the AI liter-
ature that are meant to capture the essential difficulties in a certain class of learning problems:
standard datasets for face recognition, text parsing, supervised classification, theorem-proving,
question-answering and so forth.

However, the value of these sorts of tests for AGI is predicated on the hypothesis that the
degree of success of an AI program at carrying out some domain-specific task, is correlated
with the potential of that program for being developed into a robust AGI program with broad
intelligence. If humanlike AGI and problem-area-specific “narrow AI’ are in fact very different
sorts of pursuits requiring very different principles, as we suspect, then these tests are not
strongly relevant to the AGI problem.

There are also some standard evaluation paradigms aimed at AI going beyond specific tasks.
For instance, there is a literature on “multitask learning and “transfer learning,” where the
goal for an AT is to learn one task quicker given another task solved previously [Car97, TM95,

HOUSE_OVERSIGHT_013206
