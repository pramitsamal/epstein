Forget clockwork analogies; our brains are closer to a system of canals and locks, with
signals traveling like water from one state to another.

As I sit here typing, I’m actually seeking equilibrium states in an n-dimensional
topology of gradients. Take just one: heat. My body temperature is higher than the air
temperature, so I radiate heat, which must be replenished in my core. Even the bacteria
in my digestive tract use sensors to measure sugar concentrations in the liquid around
them and whip their tail-like flagella to swim “upstream” where the sugar supply is
richest. The natural state of all systems is to flow to lower energy states, a process that is
broadly described by entropy (the tendency of things to go from ordered to disordered
states; all things will fall apart eventually, including the universe itself).

But how do you explain more complex behavior, such as our ability to make
decisions? The answer is just more gradient descent.

Our Brains

As miraculous and inscrutable as our human intelligence is, science is coming around to
the view that our brains operate the same way as any other complex system with layers
and feedback loops, all pursuing what we mathematically call “optimization functions”
but you could just as well call “flowing downhill” in some sense.

The essence of intelligence is learning, and we do that by correlating inputs with
positive or negatives scores (rewards or punishment). So, for a baby, “this sound” (your
mother’s voice) is associated with other learned connections to your mother, such as food
or comfort. Likewise, “this muscle motion brings my thumb closer to my mouth.” Over
time and trial and error, the brain’s neural network reinforces those connections.
Meanwhile “this muscle motion does not bring my thumb close to my mouth” is a
negative correlation, and the brain will weaken those connections.

However, this is too simplistic. The limits of gradient descent constitute the so-
called local-minima problem (or local-maxima problem, if you’re doing a gradient
ascent). If you are walking in a mountainous region and want to get home, always
walking downhill will most likely get you to the next valley but not necessarily over the
other mountains that lie around it and between you and home. For that, you need either a
mental model (i.e., a map) of the topology so you know where to ascend to get out of the
valley, or you need to switch between gradient descent and random walks so you can
bounce your way out of the region.

Which 1s, in fact, exactly what the mosquito does in following my scent: It
descends when it’s in my plume and random-walks when it has lost the trail or hit an
obstacle.

Al
So that’s nature. What about computers? Traditional software doesn’t work that way—it
follows deterministic trees of hard logic: “If this, do that.” But software that interacts
with the physical world tends to work more /ike the physical world. That means dealing
with noisy inputs (sensors or human behavior) and providing probabilistic, not
deterministic, results. And that, in turn, means more gradient descent.

AI software is the best example of this, especially the kinds of AI that use
artificial neural-network models (including convolutional, or “deep,” neural networks of
many layers). In these, a typical process consists of “training” them by showing them

105

HOUSE_OVERSIGHT_016325
