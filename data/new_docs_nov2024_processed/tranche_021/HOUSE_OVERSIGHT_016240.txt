methods he and others developed for the control of missiles, for example, were later put
to work in building the Saturn V moon rocket, one of the crowning engineering
achievements of the 20th century. In particular, Wiener’s applications of cybernetic
concepts to the brain and to computerized perception are the direct precursors of today’s
neural-network-based deep-learning circuits, and of artificial intelligence itself. But
current developments in these fields have diverged from his vision, and their future
development may well affect the human uses both of human beings and of machines.

What Wiener Got Wrong

It is exactly in the extension of the cybernetic idea to human beings that Wiener’s
conceptions missed their target. Setting aside his ruminations on language, law, and
human society for the moment, look at a humbler but potentially useful innovation that he
thought was imminent in 1950. Wiener notes that prosthetic limbs would be much more
effective if their wearers could communicate directly with their prosthetics by their own
neural signals, receiving information about pressure and position from the limb and
directing its subsequent motion. This turned out to be a much harder problem than
Wiener envisaged: Seventy years down the road, prosthetic limbs that incorporate neural
feedback are still in the very early stages. Wiener’s concept was an excellent one—it’s
just that the problem of interfacing neural signals with mechanical-electrical devices is
hard.

More significantly, Wiener (along with pretty much everyone else in 1950)
greatly underappreciated the potential of digital computation. As noted, Wiener’s
mathematical contributions were to the analysis of signals and noise and his analytic
methods apply to continuously varying, or analog, signals. Although he participated in
the wartime development of digital computation, he never foresaw the exponential
explosion of computing power brought on by the introduction and progressive
miniaturization of semiconductor circuits. This is hardly Wiener’s fault: The transistor
hadn’t been invented yet, and the vacuum-tube technology of the digital computers he
was familiar with was clunky, unreliable, and unscalable to ever larger devices. In an
appendix to the 1948 edition of Cybernetics, he anticipates chess-playing computers and
predicts that they’ll be able to look two or three moves ahead. He might have been
surprised to learn that within half a century a computer would beat the human world
champion at chess.

Technological Overestimation and the Existential Risks of the Singularity

When Wiener wrote his books, a significant example of technological overestimation was
about to occur. The 1950s saw the first efforts at developing artificial intelligence, by
researchers such as Herbert Simon, John McCarthy, and Marvin Minsky, who began to
program computers to perform simple tasks and to construct rudimentary robots. The
success of these initial efforts inspired Simon to declare that “machines will be capable,
within twenty years, of doing any work a man can do.” Such predictions turned out to be
spectacularly wrong. As they became more powerful, computers got better and better at
playing chess because they could systematically generate and evaluate a vast selection of
possible future moves. But the majority of predictions of AI, e.g., robotic maids, turned
out to be illusory. When Deep Blue beat Garry Kasparov at chess in 1997, the most

20

HOUSE_OVERSIGHT_016240
