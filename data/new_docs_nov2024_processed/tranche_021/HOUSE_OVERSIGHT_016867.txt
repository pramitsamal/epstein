processing performed by elementary particles moving around, and there’s no law of
physics that says one can’t build machines more intelligent in every way than we are, and
able to seed cosmic life. This suggests that we’ve seen just the tip of the intelligence
iceberg; there’s an amazing potential to unlock the full intelligence latent in nature and
use it to help humanity flourish—or flounder.

Others, including some of the authors in this volume, dismiss the building of an
AGI (Artificial General Intelligence—an entity able to accomplish any cognitive task at
least as well as humans) not because they consider it physically impossible but because
they deem it too difficult for humans to pull off in less than a century. Among
professional AI researchers, both types of dismissal have become minority views because
of recent breakthroughs. There is a strong expectation that AGI will be achieved within a
century, and the median forecast is only decades away. A recent survey of AI researchers
by Vincent Muller and Nick Bostrom concludes:

[T]he results reveal a view among experts that AI systems will probably (over
50%) reach overall human ability by 2040-50, and very likely (with 90%
probability) by 2075. From reaching human ability, it will move on to
superintelligence in 2 years (10%) to 30 years (75%) thereafter. '°

In the cosmic perspective of gigayears, it makes little difference whether AGI
arrives in thirty or three hundred years, so let’s focus on the implications rather than the
timing.

First, we humans discovered how to replicate some natural processes with
machines, making our own heat, light, and mechanical horsepower. Gradually we
realized that our bodies were also machines, and the discovery of nerve cells blurred the
boundary between body and mind. Finally, we started building machines that could
outperform not only our muscles but our minds as well. We’ve now been eclipsed by
machines in the performance of many narrow cognitive tasks, ranging from memorization
and arithmetic to game play, and we are in the process of being overtaken in many more,
from driving to investing to medical diagnosing. If the AI community succeeds in its
original goal of building AGI, then we will have, by definition, been eclipsed at all
cognitive tasks.

This begs many obvious questions. For example, will whoever or whatever
controls the AGI control Earth? Should we aim to control superintelligent machines? If
not, can we ensure that they understand, adopt, and retain human values? As Norbert
Wiener put it in Zhe Human Use of Human Beings:

Woe to us if we let [the machine] decide our conduct, unless we have previously
examined the laws of its action, and know fully that its conduct will be carried
out on principles acceptable to us! On the other hand, the machine . .. , which
can learn and can make decisions on the basis of its learning, will in no way be
obliged to make such decisions as we should have made, or will be acceptable to
us.

16 Vincent C. Miller & Nick Bostrom, “Future Progress in Artificial Intelligence: A Survey of Expert
Opinion,” in Fundamental Issues of Artificial Intelligence, Vincent C. Muller, ed. (Springer International
Publishing Switzerland, 2016), pp. 555-72. https://nickbostrom.com/papers/survey .pdf.

64

HOUSE_OVERSIGHT_016867
