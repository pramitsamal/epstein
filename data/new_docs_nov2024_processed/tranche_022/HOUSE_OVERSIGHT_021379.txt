In the case of loneliness interventions,
all of the reviews essentially confirmed
the findings of previous reviews that
social skills training and group-based
interventions can succeed in reducing
loneliness. Is this conclusion justified, or
is this a case in which prior conclusions
have been perpetuated in the manner
Kuhn describes?

To combat bias favoring results
that confirm dominant theories, some
scientists have argued that specific study
criteria should be met to warrant an
evaluation of the effectiveness of the
intervention (18). These criteria include
random assignment of study participants
to receive the intervention, evidence that
the intervention is more effective than no
intervention, findings that are replicated
by at least one independent research
group, and results that are published in
peer-reviewed journals. Previous
reviewers of loneliness interventions
have, in fact, placed a premium on
randomized trials that contrast a group
randomly selected to receive the
intervention with a group randomly
selected to receive no intervention.
However, none has employed meta-
analysis, a quantitative technique for
calculating the average effect of diverse
interventions designed to accomplish the
same goal. Whereas qualitative reviews
are subjective and vulnerable to
confirmatory biases, quantitative reviews
are objective and relatively impervious
to bias as long as all relevant studies are
included in the analysis.

To minimize bias in our meta-
analysis, we first combed the literature
to identify all the intervention studies
that specifically targeted loneliness. To
further meet our criteria for inclusion in
the meta-analysis, studies had to be
published in a peer-reviewed journal or
as a doctoral dissertation (to ensure the

133

Page

scientific integrity of the findings),
between 1970 and 2009 (to include and
extend the time interval reviewed
qualitatively in prior research), and had
to measure loneliness quantitatively.

Fifty-two intervention studies for
loneliness met our inclusion criteria.
These studies were divided into three
categories based on the experimental
design used to assess the effects of the
intervention. Twelve studies used a
single group pre-post design in which
loneliness among participants was
assessed at baseline and again after
exposure to the intervention. The single
pre-post design is weak in terms of
measuring the effectiveness of an
intervention, however, because
individuals who have high scores on a
loneliness measure on one occasion are
likely to score less extremely on a
second occasion even if no intervention
had occurred. Said differently, people
whose measurements suggest they are
very lonely at one point in time, on
average, appear to be less lonely when
measured at a later point in time. Our
meta-analysis of these studies indicated
there was indeed a lowering of
loneliness as measured before and after
the interventions, but we cannot
conclude from this evidence that the
reductions in loneliness were due to the
interventions.

Eighteen studies utilized a non-
randomized group comparison design in
which some of the participants sought
out the intervention (the experimental
group) while others (the control group)
did not. In this design, assignment of
individuals to the experimental or
control groups was based upon
convenience, participant preference, or
some other factor, which means the
groups that did and did not receive the
intervention may differ in ways that

HOUSE_OVERSIGHT_021379
